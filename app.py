import streamlit as st
import pandas as pd
import folium
from folium.plugins import HeatMap
from streamlit_folium import st_folium
import google.generativeai as genai
import plotly.express as px
from gtts import gTTS
from io import BytesIO
import numpy as np
from datetime import datetime, timedelta

# ---------- PAGE CONFIG ----------
st.set_page_config(page_title="FloodGuard AI", page_icon="üåä", layout="wide")

# ---------- THEME (‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶•‡¶ø‡¶Æ‡¶ü‡¶ø ‡¶ö‡¶Æ‡ßé‡¶ï‡¶æ‡¶∞!) ----------
st.markdown("""
<style>
body, .stApp {
    background-color: #e0f7fa !important;
    color: #0a192f !important;
    font-family: 'Inter', sans-serif;
}
footer {visibility:hidden;}
h1, h2, h3, h4, h5, h6, p, span, label, div { color: #0a192f !important; }
[data-testid="stSidebar"] {
    background-color: #b3e5fc !important;
    border-right: 1px solid #81d4fa !important;
}
[data-testid="stSidebar"] * { color: #0a192f !important; font-weight: 500 !important; }
.stButton>button {
    background-color: #0277bd !important;
    color: white !important;
    border-radius: 8px;
    font-weight: 600 !important;
}
.stButton>button:hover { background-color: #01579b !important; }
.stTabs [data-baseweb="tab-list"] button {
    background-color: #b3e5fc !important;
    color: #0a192f !important;
    border-radius: 8px;
}
.stTabs [aria-selected="true"] {
    background-color: #81d4fa !important;
    color: #003366 !important;
    border: 1px solid #0277bd40 !important;
}
.leaflet-container {
    background: #f5f5f5 !important;
    border-radius: 12px !important;
}
.leaflet-popup-content-wrapper, .leaflet-popup-tip {
    background: #fff !important;
    color: #0a192f !important;
}
.js-plotly-plot text, .legendtext, .xtick text, .ytick text { fill: #0a192f !important; }
[data-testid="stChatInput"] textarea {
    background: #ffffff !important;
    color: #0a192f !important;
    border: 1px solid #0277bd !important;
    border-radius: 10px;
    font-size: 16px;
}
[data-testid="stChatInput"] textarea::placeholder { color: #333 !important; }
[data-testid="stChatMessage"] div, [data-testid="stChatMessage"] p { color: #0a192f !important; }
@media (max-width:768px){
    body{font-size:14px!important;}
}
</style>
""", unsafe_allow_html=True)

# ---------- HEADER ----------
st.title("üåä FloodGuard AI ‚Äì Hackathon Final 2026")
st.caption("üíª Zahid Hasan | Gemini + BWDB/NASA Mock + Voice + Map + Smart Alerts")

# ---------- SESSION STATE (‡¶â‡¶®‡ßç‡¶®‡¶§) ----------
# ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶™‡ßá‡¶∞ ‡¶Ö‡¶¨‡¶∏‡ßç‡¶•‡¶æ ‡¶Æ‡¶®‡ßá ‡¶∞‡¶æ‡¶ñ‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø
if 'risk' not in st.session_state:
    st.session_state.risk = "N/A"
if 'ai_summary' not in st.session_state:
    st.session_state.ai_summary = None
if 'audio' not in st.session_state:
    st.session_state.audio = None
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'last_inputs' not in st.session_state:
    st.session_state.last_inputs = None

# ---------- GEMINI ----------
@st.cache_resource
def init_gemini():
    try:
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
        # 'gemini-pro' chat-‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶≠‡¶æ‡¶≤‡ßã, 'flash' ‡¶¶‡ßç‡¶∞‡ßÅ‡¶§‡¶§‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶≠‡¶æ‡¶≤‡ßã‡•§
        return genai.GenerativeModel("gemini-pro") 
    except Exception as e:
        st.error(f"‚ö†Ô∏è Gemini API ‡¶ï‡¶®‡¶´‡¶ø‡¶ó‡¶æ‡¶∞‡ßá‡¶∂‡¶® ‡¶¨‡ßç‡¶Ø‡¶∞‡ßç‡¶•: {e}")
        return None
gemini = init_gemini()

# ---------- MOCK DATA ----------
@st.cache_data(ttl=300) # 5 ‡¶Æ‡¶ø‡¶®‡¶ø‡¶ü ‡¶™‡¶∞ ‡¶™‡¶∞ ‡¶°‡ßá‡¶ü‡¶æ ‡¶∞‡¶ø‡¶´‡ßç‡¶∞‡ßá‡¶∂ ‡¶π‡¶¨‡ßá
def get_bwdb():
    f = np.random.uniform(-0.5, 0.5)
    return {"rivers":[
        {"name":"Padma","station":"Goalundo","level":round(8.4+f,2),"danger":10.5,"loc":[23.75,89.75]},
        {"name":"Jamuna","station":"Sirajganj","level":round(9.0+f,2),"danger":11.0,"loc":[24.45,89.70]},
        {"name":"Meghna","station":"Ashuganj","level":round(7.6+f,2),"danger":9.2,"loc":[24.02,91.00]}
    ]}

@st.cache_data
def get_dashboard_data():
    """‡¶¨‡¶æ‡¶∏‡ßç‡¶§‡¶¨‡¶∏‡¶Æ‡ßç‡¶Æ‡¶§ ‡¶ö‡¶æ‡¶∞‡ßç‡¶ü ‡¶°‡ßá‡¶ü‡¶æ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßá"""
    days = 30
    dates = pd.date_range(datetime.now() - timedelta(days=days-1), periods=days)
    # ‡¶è‡¶ï‡¶ü‡¶ø ‡¶∏‡¶ø‡¶ú‡¶®‡¶æ‡¶≤ ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡ßç‡¶° (sin wave) + ‡¶¶‡ßà‡¶¨ ‡¶ì‡¶†‡¶æ‡¶®‡¶æ‡¶Æ‡¶æ (noise)
    base_rain = 30 + 25 * np.sin(np.linspace(0, 2 * np.pi, days))
    noise = np.random.normal(0, 15, days)
    rain_data = (base_rain + noise).clip(0, 200) # 0-‡¶è‡¶∞ ‡¶®‡¶ø‡¶ö‡ßá ‡¶¨‡¶æ 200-‡¶è‡¶∞ ‡¶â‡¶™‡¶∞‡ßá ‡¶Ø‡¶æ‡¶¨‡ßá ‡¶®‡¶æ
    
    df = pd.DataFrame({"Date": dates, "Rainfall (mm)": rain_data})
    df["Risk"] = df["Rainfall (mm)"].apply(lambda r: "Low" if r < 60 else "Medium" if r < 120 else "High")
    return df

def simple_predict(r, t, h, l):
    s = (r / 100) + (l / 8) + (h / 100) - (t / 40)
    return "High" if s > 2 else "Medium" if s > 1 else "Low"

# ---------- SIDEBAR (‡¶â‡¶®‡ßç‡¶®‡¶§ - ‡¶®‡¶®-‡¶¨‡ßç‡¶≤‡¶ï‡¶ø‡¶Ç) ----------
st.sidebar.header("üì• Input Parameters")
rain = st.sidebar.slider("üåßÔ∏è Rainfall (mm)", 0, 500, 50)
temp = st.sidebar.slider("üå°Ô∏è Temperature (¬∞C)", 10, 40, 27)
hum = st.sidebar.slider("üíß Humidity (%)", 30, 100, 85)
level = st.sidebar.slider("üåä River Level (m)", 0.0, 20.0, 5.0)
loc = st.sidebar.selectbox("üìç Location", ["Dhaka", "Sylhet", "Rajshahi", "Chittagong"])

if st.sidebar.button("üîÆ Predict Flood Risk", use_container_width=True):
    # (FIX 1) ‡¶¨‡¶æ‡¶ü‡¶® ‡¶ï‡ßç‡¶≤‡¶ø‡¶ï ‡¶ï‡¶∞‡¶≤‡ßá ‡¶∂‡ßÅ‡¶ß‡ßÅ ‡¶∞‡¶ø‡¶∏‡ßç‡¶ï ‡¶ï‡ßç‡¶Ø‡¶æ‡¶≤‡¶ï‡ßÅ‡¶≤‡ßá‡¶ü ‡¶π‡ßü ‡¶è‡¶¨‡¶Ç ‡¶´‡ßç‡¶≤‡ßç‡¶Ø‡¶æ‡¶ó ‡¶∏‡ßá‡¶ü ‡¶π‡ßü
    # AI ‡¶ï‡¶≤ ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü ‡¶®‡¶æ, ‡¶§‡¶æ‡¶á ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶™ 'freeze' ‡¶π‡ßü ‡¶®‡¶æ
    st.session_state.risk = simple_predict(rain, temp, hum, level)
    st.session_state.last_inputs = (rain, temp, hum, level, loc) # ‡¶á‡¶®‡¶™‡ßÅ‡¶ü‡¶ó‡ßÅ‡¶≤‡ßã ‡¶Æ‡¶®‡ßá ‡¶∞‡¶æ‡¶ñ‡¶æ
    st.session_state.ai_summary = "LOADING" # AI ‡¶≤‡ßã‡¶°‡¶ø‡¶Ç ‡¶´‡ßç‡¶≤‡ßç‡¶Ø‡¶æ‡¶ó
    st.session_state.audio = None # ‡¶™‡ßÅ‡¶∞‡ßã‡¶®‡ßã ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶Æ‡ßÅ‡¶õ‡ßá ‡¶´‡ßá‡¶≤‡¶æ

# ---------- TABS ----------
tab1, tab2, tab3, tab4 = st.tabs(["üîÆ Prediction", "üìä Dashboard", "üó∫Ô∏è Map", "üí¨ Chatbot"])

# --- Prediction (‡¶â‡¶®‡ßç‡¶®‡¶§ - AI ‡¶ï‡¶≤ ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶π‡ßü) ---
with tab1:
    st.subheader(f"üìç {loc} Flood Forecast")
    
    # (FIX 1 Continued) AI ‡¶ú‡ßá‡¶®‡¶æ‡¶∞‡ßá‡¶∂‡¶® ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶∏‡ßç‡¶™‡¶ø‡¶®‡¶æ‡¶∞‡ßá‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡¶π‡ßü
    if st.session_state.ai_summary == "LOADING" and gemini:
        with st.spinner("ü§ñ AI is analyzing the risk..."):
            try:
                r, t, h, l, lc = st.session_state.last_inputs
                rsk = st.session_state.risk
                
                prompt = f"Location {lc}, Rain {r}mm, River {l}m, Hum {h}%, Temp {t}¬∞C. Flood risk is {rsk}. Give 2 very short, scannable safety tips in Bangla, followed by their English translation. Format: (Bangla Tip 1)\n(Bangla Tip 2)\n\n(English Tip 1)\n(English Tip 2)"
                
                res = gemini.generate_content(prompt)
                st.session_state.ai_summary = res.text[:300] # ‡¶Ö‡¶§‡¶ø‡¶∞‡¶ø‡¶ï‡ßç‡¶§ ‡¶≤‡¶Æ‡ßç‡¶¨‡¶æ ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü ‡¶¨‡¶æ‡¶¶
                
                # ‡¶∂‡ßÅ‡¶ß‡ßÅ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶Ö‡¶Ç‡¶∂‡¶ü‡ßÅ‡¶ï‡ßÅ‡¶∞ ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶ú‡ßá‡¶®‡¶æ‡¶∞‡ßá‡¶ü
                bangla_text = "\n".join(res.text.split("\n")[:2]) # ‡¶™‡ßç‡¶∞‡¶•‡¶Æ ‡ß® ‡¶≤‡¶æ‡¶á‡¶® (‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ)
                if bangla_text:
                    tts = gTTS(bangla_text, lang="bn", slow=False)
                    buf = BytesIO()
                    tts.write_to_fp(buf)
                    st.session_state.audio = buf.getvalue()
                    
            except Exception as e:
                # (FIX 3) ‡¶≠‡ßÅ‡¶≤‡ßá‡¶∞ ‡¶Æ‡ßá‡¶∏‡ßá‡¶ú ‡¶¶‡ßá‡¶ñ‡¶æ‡¶®‡ßã
                st.error(f"AI ‡¶¨‡¶æ Voice ‡¶ú‡ßá‡¶®‡¶æ‡¶∞‡ßá‡¶∂‡¶®‡ßá ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ: {e}")
                st.session_state.ai_summary = "AI analysis failed."
                
    # ‡¶∞‡¶ø‡¶∏‡ßç‡¶ï ‡¶¶‡ßá‡¶ñ‡¶æ‡¶®‡ßã
    r = st.session_state.risk
    if r != "N/A":
        color = {"Low":"#4caf50", "Medium":"#ff9800", "High":"#f44336"}[r]
        st.markdown(f"<h3 style='color:{color};'>üåÄ {r} Flood Risk</h3>", unsafe_allow_html=True)
        if r == "High": st.error("üö® HIGH RISK! Evacuate low-lying areas.")
        elif r == "Medium": st.warning("‚ö†Ô∏è Moderate risk ‚Äî stay alert.")
        else: st.success("‚úÖ Low risk ‚Äî Safe conditions.")

    # AI ‡¶ú‡ßá‡¶®‡¶æ‡¶∞‡ßá‡¶ü‡ßá‡¶° ‡¶ï‡¶®‡ßç‡¶ü‡ßá‡¶®‡ßç‡¶ü ‡¶¶‡ßá‡¶ñ‡¶æ‡¶®‡ßã
    if st.session_state.ai_summary and st.session_state.ai_summary != "LOADING":
        st.markdown("### ü§ñ AI Safety Tips")
        st.markdown(st.session_state.ai_summary)
    
    if st.session_state.audio:
        st.audio(st.session_state.audio, format="audio/mp3")

# --- Dashboard (‡¶â‡¶®‡ßç‡¶®‡¶§ - ‡¶ï‡ßç‡¶≤‡¶ø‡¶®‡¶æ‡¶∞ ‡¶°‡ßá‡¶ü‡¶æ) ---
with tab2:
    st.subheader("üìà Live River Levels & 30-Day Trend")
    bwdb = get_bwdb()
    
    # ‡¶≤‡¶æ‡¶á‡¶≠ ‡¶≤‡ßá‡¶≠‡ßá‡¶≤ (Metrics)
    cols = st.columns(len(bwdb["rivers"]))
    for i, r in enumerate(bwdb["rivers"]):
        delta_val = r["level"] - r["danger"]
        cols[i].metric(
            label=f"üåä {r['name']} ({r['station']})",
            value=f"{r['level']} m",
            delta=f"{delta_val:+.2f} m (Danger: {r['danger']}m)",
            delta_color="inverse" # ‡¶ï‡¶Æ ‡¶Æ‡¶æ‡¶®‡ßá ‡¶≠‡¶æ‡¶≤‡ßã (‡¶∏‡¶¨‡ßÅ‡¶ú), ‡¶¨‡ßá‡¶∂‡¶ø ‡¶Æ‡¶æ‡¶®‡ßá ‡¶ñ‡¶æ‡¶∞‡¶æ‡¶™ (‡¶≤‡¶æ‡¶≤)
        )
    
    st.divider()
    
    # (FIX 4) ‡¶¨‡¶æ‡¶∏‡ßç‡¶§‡¶¨‡¶∏‡¶Æ‡ßç‡¶Æ‡¶§ ‡¶ö‡¶æ‡¶∞‡ßç‡¶ü ‡¶°‡ßá‡¶ü‡¶æ
    df = get_dashboard_data()
    fig = px.line(df, x="Date", y="Rainfall (mm)", color="Risk",
        color_discrete_map={"Low":"#4caf50", "Medium":"#ff9800", "High":"#f44336"},
        title="Simulated 30-Day Rainfall & Flood Risk Trend")
    fig.update_layout(plot_bgcolor="#f5f5f5", paper_bgcolor="#f5f5f5")
    st.plotly_chart(fig, use_container_width=True)

# --- Map (‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶ï‡ßã‡¶°‡¶ü‡¶ø ‡¶≠‡¶æ‡¶≤‡ßã ‡¶õ‡¶ø‡¶≤) ---
with tab3:
    st.subheader("üó∫Ô∏è Interactive Flood Risk Map")
    bwdb = get_bwdb()
    m = folium.Map(location=[23.7, 90.4], zoom_start=7, tiles="CartoDB positron")
    heat = []
    
    for r in bwdb["rivers"]:
        level = r["level"]
        danger = r["danger"]
        risk_text = "High" if level > danger else "Medium" if level > danger * 0.9 else "Low"
        color = {"Low": "green", "Medium": "orange", "High": "red"}[risk_text]
        
        folium.Marker(
            r["loc"],
            tooltip=f"{r['name']} ‚Äì {r['level']} m",
            popup=f"<b>{r['name']}</b><br>Station: {r['station']}<br>Level: {level}m<br>Danger: {danger}m<br>Risk: {risk_text}",
            icon=folium.Icon(color=color, icon="tint", prefix="fa")
        ).add_to(m)
        
        # ‡¶∞‡¶ø‡¶∏‡ßç‡¶ï ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ‡¶π‡¶ø‡¶ü‡¶Æ‡ßç‡¶Ø‡¶æ‡¶™‡ßá‡¶∞ ‡¶ò‡¶®‡¶§‡ßç‡¶¨
        pts = 70 if risk_text == "High" else 50 if risk_text == "Medium" else 30
        heat.extend(np.random.normal(loc=r["loc"], scale=[0.4, 0.4], size=(pts, 2)).tolist())
        
    if heat:
        HeatMap(heat, radius=20, blur=15, min_opacity=0.3,
                gradient={0.2:'#4caf50', 0.5:'#ff9800', 0.8:'#f44336'}).add_to(m)
    
    st_folium(m, width="100%", height=540)

# --- Chatbot (‡¶â‡¶®‡ßç‡¶®‡¶§ - ‡¶ö‡ßç‡¶Ø‡¶æ‡¶ü ‡¶π‡¶ø‡¶∏‡ßç‡¶ü‡ßç‡¶∞‡¶ø ‡¶∏‡¶π) ---
with tab4:
    st.subheader("üí¨ FloodGuard AI Chat (Bangla + English)")
    
    # ‡¶ö‡ßç‡¶Ø‡¶æ‡¶ü ‡¶π‡¶ø‡¶∏‡ßç‡¶ü‡ßç‡¶∞‡¶ø ‡¶¶‡ßá‡¶ñ‡¶æ‡¶®‡ßã
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]): 
            st.markdown(msg["content"])
    
    if q := st.chat_input("‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶ï‡¶∞‡ßÅ‡¶® / Ask a question..."):
        # ‡¶á‡¶â‡¶ú‡¶æ‡¶∞‡ßá‡¶∞ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶æ
        st.session_state.messages.append({"role":"user", "content": q})
        with st.chat_message("user"): 
            st.markdown(q)
        
        with st.chat_message("assistant"):
            if gemini:
                with st.spinner("AI ‡¶≠‡¶æ‡¶¨‡¶õ‡ßá..."):
                    try:
                        # (FIX 2) ‡¶ö‡ßç‡¶Ø‡¶æ‡¶ü‡¶¨‡¶ü‡¶ï‡ßá ‡¶™‡ßÅ‡¶∞‡ßã ‡¶π‡¶ø‡¶∏‡ßç‡¶ü‡ßç‡¶∞‡¶ø ‡¶™‡¶æ‡¶†‡¶æ‡¶®‡ßã
                        # ‡¶è‡¶ï‡¶ü‡¶ø ‡¶∏‡¶ø‡¶∏‡ßç‡¶ü‡ßá‡¶Æ ‡¶™‡ßç‡¶∞‡¶Æ‡ßç‡¶™‡¶ü ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶æ
                        system_prompt = "You are FloodGuard AI, a helpful expert on Bangladesh floods. Answer the user's latest question concisely (max 100 words), using both Bangla and English if appropriate. Use the chat history for context."
                        
                        # ‡¶π‡¶ø‡¶∏‡ßç‡¶ü‡ßç‡¶∞‡¶ø‡¶ï‡ßá ‡¶´‡¶∞‡¶Æ‡ßç‡¶Ø‡¶æ‡¶ü ‡¶ï‡¶∞‡¶æ
                        history_for_prompt = []
                        for m in st.session_state.messages:
                            history_for_prompt.append({"role": m["role"], "parts": [m["content"]]})
                        
                        # ‡¶ú‡ßá‡¶Æ‡¶ø‡¶®‡¶ø ‡¶ö‡ßç‡¶Ø‡¶æ‡¶ü ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ï‡¶∞‡¶æ
                        chat = gemini.start_chat(history=history_for_prompt[:-1]) # ‡¶∂‡ßá‡¶∑ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶¨‡¶æ‡¶¶‡ßá ‡¶∏‡¶¨
                        res = chat.send_message(f"{system_prompt}\n\nUSER'S NEW QUESTION: {q}")
                        
                        ans = res.text
                        st.markdown(ans)
                        st.session_state.messages.append({"role":"assistant", "content": ans})
                        
                    except Exception as e:
                        st.error(f"AI Chat Error: {e}")
            else:
                ans = "Demo mode active ‚Äî no API key. (API ‡¶ï‡ßÄ ‡¶õ‡¶æ‡ßú‡¶æ ‡¶°‡ßá‡¶Æ‡ßã ‡¶Æ‡ßã‡¶° ‡¶ö‡¶≤‡¶õ‡ßá)"
                st.markdown(ans)
                st.session_state.messages.append({"role":"assistant", "content": ans})

    if st.button("üóëÔ∏è Clear Chat History"):
        st.session_state.messages = []
        st.rerun()

# ---------- FOOTER ----------
st.divider()
st.caption("üåä FloodGuard AI ¬© 2026 | Gemini + Mock BWDB/NASA | Developed by Zahid Hasan üíª | [GitHub](https://github.com/zahid397/FloodGuard-AI)")
        
